{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp-notes-1.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdmZ1SmnsCxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzpoZCMWsH3c",
        "colab_type": "text"
      },
      "source": [
        "# Tokenization\n",
        "\n",
        "Es el proceso de separar una sentencia en unidades minimas llamadas tokens.\n",
        "Un token es una unidad util para el procesamiento semantico, puede ser una palabra, sentencia o parrafo.\n",
        "\n",
        "Se puede separar por espacios, puntuaciones.\n",
        "En ingles es facil separar por espacios, en cambio en aleman no, porque existen palabras que se escriben sin separación una de la otra, al igual el japones, no tiene espacios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2DNPtyRsG8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"This is Andrew's text, isn't it?\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiTvLhNOswu5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ddaf31fa-686d-4b50-e21e-f65a92777575"
      },
      "source": [
        "tokenizer = nltk.tokenize.WhitespaceTokenizer() # problema con is y isn't ambos el mismo significado\n",
        "tokenizer.tokenize(text)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This', 'is', \"Andrew's\", 'text,', \"isn't\", 'it?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUsNEZLdtJVN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c6f555b-f743-493c-ff94-ebdec161bf39"
      },
      "source": [
        "tokenizer = nltk.tokenize.WordPunctTokenizer() # problema con 's', 'isn', 't'\n",
        "tokenizer.tokenize(text)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This', 'is', 'Andrew', \"'\", 's', 'text', ',', 'isn', \"'\", 't', 'it', '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s_gb371t0lv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef5f7538-5bff-4f10-ef45-b6bc7b82060d"
      },
      "source": [
        "tokenizer = nltk.tokenize.TreebankWordTokenizer() # \"'s\" y \"n't\" tienen mas significado\n",
        "tokenizer.tokenize(text)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This', 'is', 'Andrew', \"'s\", 'text', ',', 'is', \"n't\", 'it', '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZVCb4xXwJzp",
        "colab_type": "text"
      },
      "source": [
        "# Token Normalization\n",
        "## Stemming \n",
        "Proceso de remover y reemplazar el sufijo, para obtener la raiz de la palabra, llamada \"stem\"\n",
        "\n",
        "Ejemplo:\n",
        "\n",
        "Porter's stemmer\n",
        "\n",
        "Tiene 5 fases heuristicas de palabras reducidas y aplicadas secuencialmente.\n",
        "\n",
        "Regla\n",
        "\n",
        "> SSES -> SS       caresses -> caress\n",
        "\n",
        "> IES -> I              ponies     -> poni\n",
        "\n",
        "> SS -> SS           caress     -> caress\n",
        "\n",
        "> S ->                   cats         -> cat\n",
        "\n",
        "Sin embargo es un probelma para verbos irregulares y produce palabras sin significado, wolves -> wolv\n",
        "\n",
        "## Lemmatization\n",
        "Es la forma base de diccionario de una palabra, conocido como \"lemma\"\n",
        "\n",
        "Ejemplo\n",
        "\n",
        "WordNet Lemmatizer\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KVPyU4auv2w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5590e37-8d7e-40d2-dd7c-e99cc9dae73f"
      },
      "source": [
        "text = \"feet cats wolves talked\"\n",
        "tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
        "tokens = tokenizer.tokenize(text)\n",
        "tokens"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['feet', 'cats', 'wolves', 'talked']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2EDudNc2jr8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5388a318-b192-4a94-dbe8-884c12618340"
      },
      "source": [
        "stemmer = nltk.stem.PorterStemmer()\n",
        "\" \".join(stemmer.stem(token) for token in tokens)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'feet cat wolv talk'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPcCxLqS2-LU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "50c55975-3e3f-41bf-9fd0-2bd16b745768"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTVdQmqR2x4s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "198cdf46-3803-4d4a-ee2d-baa2f36424e2"
      },
      "source": [
        "stemmer = nltk.stem.WordNetLemmatizer()\n",
        "\" \".join(stemmer.lemmatize(token) for token in tokens)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'foot cat wolf talked'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7h__MJc3Uav",
        "colab_type": "text"
      },
      "source": [
        "Problemas\n",
        "\n",
        "Uso de mayúsculas\n",
        "\n",
        "Us, us, US\n",
        "\n",
        "Soluciones:\n",
        "\n",
        "> Lowercasing al comienzo de la oración\n",
        "> Lowercasing palabras en los títulos\n",
        "> Dejar las palabras que estan en el medio de la oracion tal cual.\n",
        "\n",
        "Uo de acrónimos\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kl2aIW3-5AvT",
        "colab_type": "text"
      },
      "source": [
        "# Transformar tokens en features\n",
        "## BOW \n",
        "Cuenta el número de veces que se repite una palabra en el texto.\n",
        "Cada token sera una columna en nuestro vector característico, este proceso se llama \"text \n",
        "vectorization\"\n",
        "                          \n",
        "                  good |movie|not|a|did|like\n",
        "---\n",
        "\n",
        "\n",
        "buena pelicula                      1 1 0 0 0 0\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "la pelicula no es buena       1 1 1 1 0 0\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "no me gusta                         0 0 1 0 1 1\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Problemas:\n",
        "> Se pierde el orden de las palabras\n",
        ">> Contar pares, triples de palabras para conservar un orden local entre palabras, desventaja esta representacion aumenta el numero de features. Pero se puede remover algunos n-grams de acuerdo a la frequencia en la que aparecen en el corpus.\n",
        ">>> Remover n-grams de frequencia alta\n",
        "\n",
        ">>>> Articulos, preposiciones, los llamados stop-words que no ayudan a discriminar textos.\n",
        "\n",
        ">>> Remover n-grams de baja frequencia\n",
        "\n",
        ">>>> typos = palabras con error ortográfico o n-grams raros, removerlos porque podrían generar overfitting\n",
        "\n",
        ">>> Quedarse con n-grams de frequencia media\n",
        "\n",
        ">>>> Como saber cual es la mejor frequencia media\n",
        "\n",
        "> El contador no esta normalizado\n",
        "\n",
        "\n",
        "Filtrar los n-grams de frequencia media por medio de un ranking.\n",
        "El n-gram con menor frequencia puede ser una palabra específica y útil para discriminar el texto ejempo Wi-fi breaks.\n",
        "\n",
        "##N-GRAMS\n",
        "###Métodos para rankear n-grams\n",
        "#### Term Frequency TF\n",
        "\n",
        "tf(t,d) frequencia de un ttermino en un documento\n",
        "\n",
        "binary -> 1,0 # token presente o no en el documento\n",
        "\n",
        "raw count -> f,t,d # distribucion de probabilidade de los tokens\n",
        "\n",
        "term frequency -> $f_{t,d}/\\sum_{t' \\in d} f_{t',d}$ # distribución normalizada\n",
        "\n",
        "log normalization -> $1 + log(f_{t,d})$ \n",
        "\n",
        "#### Inverse document frequency\n",
        "Cuantos documentos contienen un especifico termino.\n",
        "\n",
        ">$N = |D|$ -> número total de documentos en el corpus.\n",
        ">|{d \\in D:t \\in d}| -> número de documentos donde el término $t$ aparece.\n",
        "\n",
        "$$idf(t,D) = \\log\\frac{N}{|\\{d \\in D: t \\in d\\}|}$$\n",
        "\n",
        "#### TF-IDF\n",
        "$$tfidf(t,d,D) = tf(t,d) \\dot idf(t,D)$$\n",
        "\n",
        "Un valor alto de TF-IDF se da cuando el término tiene una frequencia alta en el propio texto y una frequencia baja entre los demas documentos.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRImJ_h63Ci5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2d4fc770-69e3-4387-ff6b-fa50afc6aeea"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "texts = [\"good movie\", \"not a good movie\", \"did not like\", \"i like it\", \"good one\"]\n",
        "\"\"\"\n",
        "min_df (ratio de documentos) parámetro para setear un umbral minimo de frequencias del documento, low frequency n-grams \n",
        "max_df (ratio de documentos) stop-words \n",
        "ngram_range rango de ngram-s de tamanho 1 y 2 por ejemplo.\n",
        "\"\"\"\n",
        "tfidf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1,2))\n",
        "features = tfidf.fit_transform(texts)\n",
        "pd.DataFrame(features.todense(),columns=tfidf.get_feature_names())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>good movie</th>\n",
              "      <th>like</th>\n",
              "      <th>movie</th>\n",
              "      <th>not</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.577350</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.577350</td>\n",
              "      <td>0.577350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.707107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   good movie      like     movie       not\n",
              "0    0.707107  0.000000  0.707107  0.000000\n",
              "1    0.577350  0.000000  0.577350  0.577350\n",
              "2    0.000000  0.707107  0.000000  0.707107\n",
              "3    0.000000  1.000000  0.000000  0.000000\n",
              "4    0.000000  0.000000  0.000000  0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9wwlxMSFZIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}