{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xml-roberta.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNLBMm9+nYA/kqZBEdHJ9wt"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "15bfeaa9432a4fc4923d68c2e7a90b7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_baec4062017e463196d8e1790bf6f61c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ab9b32df3af04bfe9400e3e62afb0448",
              "IPY_MODEL_249f4e3679274c72bad685f7ef335822"
            ]
          }
        },
        "baec4062017e463196d8e1790bf6f61c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab9b32df3af04bfe9400e3e62afb0448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_baeb1815007f4b88ba7576669048007f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5069051,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5069051,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6a62f9bbe0b2454c8e023403b3408490"
          }
        },
        "249f4e3679274c72bad685f7ef335822": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9a10ed9c724d4165bad6a9aa95b549c4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.07M/5.07M [00:02&lt;00:00, 2.30MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_23a8ad3e6d164359ab1e23285f859420"
          }
        },
        "baeb1815007f4b88ba7576669048007f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6a62f9bbe0b2454c8e023403b3408490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a10ed9c724d4165bad6a9aa95b549c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "23a8ad3e6d164359ab1e23285f859420": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "538e8735f289438a9c10fbb701bdeee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_80e20ba3cb5d4faca1a7acf88aae33f8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_97410d993fb141f392b8d1d28bfdfcd3",
              "IPY_MODEL_bd8e277a14514afc855e4ad7ed57ac59"
            ]
          }
        },
        "80e20ba3cb5d4faca1a7acf88aae33f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "97410d993fb141f392b8d1d28bfdfcd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5a7709f3bb054a059d3be0b01b5e0077",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9096718,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9096718,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f86f654d51c43f7b10883929ce7baf8"
          }
        },
        "bd8e277a14514afc855e4ad7ed57ac59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_490cf7756b4a4cb69fc0c8e498575b71",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9.10M/9.10M [00:01&lt;00:00, 7.25MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e5219f889e5b47bea73d399a6d7a62c0"
          }
        },
        "5a7709f3bb054a059d3be0b01b5e0077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f86f654d51c43f7b10883929ce7baf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "490cf7756b4a4cb69fc0c8e498575b71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e5219f889e5b47bea73d399a6d7a62c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a06cbd941104680b27354cffe061b71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cc8de10ae2634eb1b42ee136af842afa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3a4f9ce3dc3447b187eb59da3046dc34",
              "IPY_MODEL_43a0ab59e46d4af7a13b201da2f7161b"
            ]
          }
        },
        "cc8de10ae2634eb1b42ee136af842afa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a4f9ce3dc3447b187eb59da3046dc34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9fa844a5a86f4a08a170201549529d8c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 871891,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 871891,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_489f5cac16504ef3aef2bccfc7022084"
          }
        },
        "43a0ab59e46d4af7a13b201da2f7161b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_96587defce0242bb96a21c6a522c569a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 872k/872k [00:00&lt;00:00, 1.37MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_deee31810754408682e46ff2fa9692af"
          }
        },
        "9fa844a5a86f4a08a170201549529d8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "489f5cac16504ef3aef2bccfc7022084": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "96587defce0242bb96a21c6a522c569a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "deee31810754408682e46ff2fa9692af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7159ddddb19f4c18af6546ef23675072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6462562cc1d64dc3bf28200130ff5fe6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_39c74751d8b14d9eb1d2b8be347c4a87",
              "IPY_MODEL_5dffa75af6ac4c6ab25d5913a6f585b4"
            ]
          }
        },
        "6462562cc1d64dc3bf28200130ff5fe6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "39c74751d8b14d9eb1d2b8be347c4a87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_766427e28bb549c9acfe540bd7627ed3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_01898c1a5ca6498d978c9bb77208006c"
          }
        },
        "5dffa75af6ac4c6ab25d5913a6f585b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_893c3e0618504bf9866f695c2a6c88ad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 43.6B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_41fce71aa236448399fec501e7f99523"
          }
        },
        "766427e28bb549c9acfe540bd7627ed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "01898c1a5ca6498d978c9bb77208006c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "893c3e0618504bf9866f695c2a6c88ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "41fce71aa236448399fec501e7f99523": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f43c59f9eb946b48b939a4284feff17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ae8fbeff7ffc415c9df0cc35a03c120e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3cda1e9d370144b292643e2bc0d92586",
              "IPY_MODEL_0d877cc58aa340648536b3eef644a020"
            ]
          }
        },
        "ae8fbeff7ffc415c9df0cc35a03c120e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3cda1e9d370144b292643e2bc0d92586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ab634f8787484194a8700eff2717c941",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1715180,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1715180,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_160fdd7229524fa1978d9ef295280b82"
          }
        },
        "0d877cc58aa340648536b3eef644a020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b3735e905ef24155a7bd33bb85a04f33",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.72M/1.72M [00:00&lt;00:00, 5.02MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_82981cf66ac64cfb96f77bd390063cba"
          }
        },
        "ab634f8787484194a8700eff2717c941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "160fdd7229524fa1978d9ef295280b82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3735e905ef24155a7bd33bb85a04f33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "82981cf66ac64cfb96f77bd390063cba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0a42660b1e444df0af43ea9bd7ee2dfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_84fac8b79e6340cda5bfb1388bbe448d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_db97c9ef97b747b88753d5fb15a9c1a7",
              "IPY_MODEL_8f574fb8ab354f48a60faf07ab41ca3a"
            ]
          }
        },
        "84fac8b79e6340cda5bfb1388bbe448d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db97c9ef97b747b88753d5fb15a9c1a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9c62531570664a42b9a4807022224ec3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 625,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 625,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_98ff4409640144978bcc665adcae8416"
          }
        },
        "8f574fb8ab354f48a60faf07ab41ca3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f3c2ea8747fb4365b57d3f38b717f0b1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 625/625 [00:00&lt;00:00, 3.89kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6193af98db5743e9a7b17a1e14b6916e"
          }
        },
        "9c62531570664a42b9a4807022224ec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "98ff4409640144978bcc665adcae8416": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3c2ea8747fb4365b57d3f38b717f0b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6193af98db5743e9a7b17a1e14b6916e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba7a33699e83492790e074166094ad08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b366cbcb969f42578660efb3008f0299",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6770da38ecd7474b8f23d1945cfd3862",
              "IPY_MODEL_7246e8eecb8b4e91b9e226cd0d6dc49d"
            ]
          }
        },
        "b366cbcb969f42578660efb3008f0299": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6770da38ecd7474b8f23d1945cfd3862": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_27d2e528084b4653be330f18eb7116f7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 672271273,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 672271273,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1aed279f7c2549968687c002e736eb3f"
          }
        },
        "7246e8eecb8b4e91b9e226cd0d6dc49d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cdfa44037c494c569afbcb9d094b179e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 672M/672M [00:17&lt;00:00, 38.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f053aec2600d412bb6b3b9af948481e6"
          }
        },
        "27d2e528084b4653be330f18eb7116f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1aed279f7c2549968687c002e736eb3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cdfa44037c494c569afbcb9d094b179e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f053aec2600d412bb6b3b9af948481e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7380ba9f9a5840f9863a96d9acdc9d9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4c2631d423604f8db934ea627185eb46",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_74c5e76e824a42b092ff78362f5419c6",
              "IPY_MODEL_d49bfe5c5fec4e16b35d5bbeeeb27490"
            ]
          }
        },
        "4c2631d423604f8db934ea627185eb46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "74c5e76e824a42b092ff78362f5419c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_666929547d0843aab08c95eeb13bdd7b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 512,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 512,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_11b97ccc12ee44428358867d75130914"
          }
        },
        "d49bfe5c5fec4e16b35d5bbeeeb27490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9b333e0b5cf2440e92ba4369dcdf6d6d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 512/512 [00:33&lt;00:00, 15.4B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae0f30dc39d34807bda989bbe5c5e21f"
          }
        },
        "666929547d0843aab08c95eeb13bdd7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "11b97ccc12ee44428358867d75130914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b333e0b5cf2440e92ba4369dcdf6d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae0f30dc39d34807bda989bbe5c5e21f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "47fc8cfc56514fd98359bdde9e2aeb3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2531990d4a294b8c9bf94d954c31d57b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6d88d22c07db4b02b19aba29e8911b3e",
              "IPY_MODEL_f808bde5d0c943d8b828278447315438"
            ]
          }
        },
        "2531990d4a294b8c9bf94d954c31d57b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d88d22c07db4b02b19aba29e8911b3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b2e4d310997e48ab898b902379873b7c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1115590446,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1115590446,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_51d2e8e6df0a475fb79aac98688b3965"
          }
        },
        "f808bde5d0c943d8b828278447315438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2f59a19c04684157bbf718c04d5375ce",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.12G/1.12G [00:32&lt;00:00, 34.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_90024ab626a940e89b76cb4306cae6cf"
          }
        },
        "b2e4d310997e48ab898b902379873b7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "51d2e8e6df0a475fb79aac98688b3965": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f59a19c04684157bbf718c04d5375ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "90024ab626a940e89b76cb4306cae6cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXsLQDobyTvn"
      },
      "source": [
        "#!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "#!python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMBnQp6Q2Pyo"
      },
      "source": [
        "#!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEU0aSL-ybGA"
      },
      "source": [
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32Rf47yb2ObT",
        "outputId": "d1dc3a7d-d44a-4d65-fcef-d6ba116a6600"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import gc\n",
        "\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# set a seed value\n",
        "torch.manual_seed(555)\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "\n",
        "import transformers\n",
        "from transformers import BertTokenizer, BertForSequenceClassification \n",
        "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
        "from transformers import AdamW\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "print(torch.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.6.0a0+bf2bbd9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Moip4JoB30VZ"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Instantiate the Bert tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv5iF-3D36fC",
        "outputId": "888f27db-01e0-4232-bfbb-bedbae726356"
      },
      "source": [
        "len(tokenizer.vocab)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30522"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQkDpIgx3-b7",
        "outputId": "899ebe46-8bda-43c1-cec8-cdf4c8d742fd"
      },
      "source": [
        "# The vocab is an ordered dictionary - key/value pairs.\n",
        "# This is how to see which tokens are associated with a particular word.\n",
        "\n",
        "bert_vocab = tokenizer.vocab\n",
        "\n",
        "print(bert_vocab['[CLS]'])\n",
        "print(bert_vocab['[SEP]'])\n",
        "print(bert_vocab['[PAD]'])\n",
        "\n",
        "print(bert_vocab['hello'])\n",
        "print(bert_vocab['world'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101\n",
            "102\n",
            "0\n",
            "7592\n",
            "2088\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fE2PnWV94Fus",
        "outputId": "d01fa2e3-ee0b-49d7-8fc3-0dd54da2a99f"
      },
      "source": [
        "MAX_LEN = 10 # This value could be set as 256, 512 etc.\n",
        "\n",
        "sentence1 = 'Hello there.'\n",
        "\n",
        "encoded_dict = tokenizer.encode_plus(\n",
        "            sentence1,                      # Sentence to encode.\n",
        "            add_special_tokens = True,      # Add '[CLS]' and '[SEP]'\n",
        "            max_length = MAX_LEN,           # Pad or truncate.\n",
        "            pad_to_max_length = True,\n",
        "            truncation=True,\n",
        "            return_attention_mask = True,   # Construct attn. masks.\n",
        "            return_tensors = 'pt',          # Return pytorch tensors.\n",
        "           )\n",
        "\n",
        "\n",
        "encoded_dict"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 101, 7592, 2045, 1012,  102,    0,    0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6UOFQTa21BZ"
      },
      "source": [
        "#!pip install sentencepiece"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpryEkhV-_xm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "15bfeaa9432a4fc4923d68c2e7a90b7d",
            "baec4062017e463196d8e1790bf6f61c",
            "ab9b32df3af04bfe9400e3e62afb0448",
            "249f4e3679274c72bad685f7ef335822",
            "baeb1815007f4b88ba7576669048007f",
            "6a62f9bbe0b2454c8e023403b3408490",
            "9a10ed9c724d4165bad6a9aa95b549c4",
            "23a8ad3e6d164359ab1e23285f859420",
            "538e8735f289438a9c10fbb701bdeee8",
            "80e20ba3cb5d4faca1a7acf88aae33f8",
            "97410d993fb141f392b8d1d28bfdfcd3",
            "bd8e277a14514afc855e4ad7ed57ac59",
            "5a7709f3bb054a059d3be0b01b5e0077",
            "1f86f654d51c43f7b10883929ce7baf8",
            "490cf7756b4a4cb69fc0c8e498575b71",
            "e5219f889e5b47bea73d399a6d7a62c0"
          ]
        },
        "outputId": "e3d0c7b2-8107-43a0-fa13-96f1350d341e"
      },
      "source": [
        "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
        "\n",
        "MODEL_TYPE = 'xlm-roberta-base'\n",
        "\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained(MODEL_TYPE)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15bfeaa9432a4fc4923d68c2e7a90b7d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descriptâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "538e8735f289438a9c10fbb701bdeee8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=9096718.0, style=ProgressStyle(descriptâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJEVjSDi_NPA",
        "outputId": "e18fce32-9ec1-4c3e-e9c2-8406d57ca16d"
      },
      "source": [
        "tokenizer.vocab_size"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "250002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-NAdB4x_RYz",
        "outputId": "5e0e0303-a830-42b7-8d1b-fb94a785bf91"
      },
      "source": [
        "tokenizer.special_tokens_map"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bos_token': '<s>',\n",
              " 'cls_token': '<s>',\n",
              " 'eos_token': '</s>',\n",
              " 'mask_token': '<mask>',\n",
              " 'pad_token': '<pad>',\n",
              " 'sep_token': '</s>',\n",
              " 'unk_token': '<unk>'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaG9depE_Utf",
        "outputId": "134d7274-8c4c-4f1c-d0d2-43fbe4964448"
      },
      "source": [
        "print('bos_token_id <s>:', tokenizer.bos_token_id)\n",
        "print('eos_token_id </s>:', tokenizer.eos_token_id)\n",
        "print('sep_token_id </s>:', tokenizer.sep_token_id)\n",
        "print('pad_token_id <pad>:', tokenizer.pad_token_id)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bos_token_id <s>: 0\n",
            "eos_token_id </s>: 2\n",
            "sep_token_id </s>: 2\n",
            "pad_token_id <pad>: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGNdKqghO3ff",
        "outputId": "669ac2c5-b053-4c26-8fe5-8a65728b54da"
      },
      "source": [
        "## Mount Drive into Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWAMKl8v_ZKQ"
      },
      "source": [
        "dataset_path = \"/content/drive/My Drive/Colab Notebooks/projeto-reconhecimento-autoria/dataset/\""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieyOBGqzOwJC"
      },
      "source": [
        "data = pd.read_csv(dataset_path + \"books_authorship_english.csv\") "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vb-ougWKO0dp",
        "outputId": "ba88dcda-e5a5-4e6a-e177-3702ab87bdf5"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(78, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-eEcvVgRJdm"
      },
      "source": [
        "min_size = 300"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrcD1SdDUDlW",
        "outputId": "212c192f-8eb4-483e-c11f-2c5feace1376"
      },
      "source": [
        "label_to_ix = {}\n",
        "for label in data.label:\n",
        "    for word in label.split():\n",
        "        if word not in label_to_ix:\n",
        "            label_to_ix[word]=len(label_to_ix)\n",
        "label_to_ix"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alan_poe': 3,\n",
              " 'arthur_doyle': 9,\n",
              " 'bram_stoker': 4,\n",
              " 'charles_darwin': 8,\n",
              " 'charles_dickens': 6,\n",
              " 'daniel_defoe': 2,\n",
              " 'george_eliot': 10,\n",
              " 'hector_hugh': 0,\n",
              " 'jane_austen': 11,\n",
              " 'joseph_conrad': 12,\n",
              " 'mark_twain': 5,\n",
              " 'pelham_grenville': 7,\n",
              " 'thomas_hardy': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYOncetI5Hod"
      },
      "source": [
        "random_flag = False"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MA7vQaaYPGrT",
        "outputId": "641cbfd3-a44d-4e32-8d90-60d426fe34aa"
      },
      "source": [
        "df_train = pd.DataFrame(columns = ['text', 'label'])\n",
        "corpus = [i.split() for i in data[\"words\"]]\n",
        "segmented_corpus = []\n",
        "\n",
        "for book in corpus:\n",
        "  partitions = int(round(len(book)/min_size,2) + 0.5)\n",
        "  segments = [book[int(round(min_size * i)): int(round(min_size * (i + 1)))] for i in range(partitions)]\n",
        "  segmented_corpus.append(segments)\n",
        "\n",
        "for label, partitions in zip(data[\"label\"], segmented_corpus):\n",
        "  if random_flag:\n",
        "    random_index = random.randint(0, len(partitions) - 1)\n",
        "    text = \" \".join(partitions[random_index])\n",
        "    intent = label\n",
        "    df_train = df_train.append({'text': text, 'label': intent}, ignore_index=True)\n",
        "  else:\n",
        "    for p in partitions:\n",
        "      text = \" \".join(p)\n",
        "      intent = label\n",
        "      df_train = df_train.append({'text': text, 'label': intent}, ignore_index=True)\n",
        "df_train.tail()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33343</th>\n",
              "      <td>we leave directly pay no attention to her cry ...</td>\n",
              "      <td>joseph_conrad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33344</th>\n",
              "      <td>come here look at abdulla now he life here bec...</td>\n",
              "      <td>joseph_conrad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33345</th>\n",
              "      <td>waste of money that devil only know what becom...</td>\n",
              "      <td>joseph_conrad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33346</th>\n",
              "      <td>do everybody finally she i verily believe come...</td>\n",
              "      <td>joseph_conrad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33347</th>\n",
              "      <td>speak very loud and thump the table i want to ...</td>\n",
              "      <td>joseph_conrad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text          label\n",
              "33343  we leave directly pay no attention to her cry ...  joseph_conrad\n",
              "33344  come here look at abdulla now he life here bec...  joseph_conrad\n",
              "33345  waste of money that devil only know what becom...  joseph_conrad\n",
              "33346  do everybody finally she i verily believe come...  joseph_conrad\n",
              "33347  speak very loud and thump the table i want to ...  joseph_conrad"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keLvInbj5NhR",
        "outputId": "beb7e260-18b6-403f-8f3c-90b3a1d74bf3"
      },
      "source": [
        "df_train.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(33348, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gd71F45nRHHz",
        "outputId": "c1acd6ab-be09-4fd5-d4cd-d857b86024ad"
      },
      "source": [
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "\n",
        "# shuffle\n",
        "df = shuffle(df_train)\n",
        "\n",
        "# initialize kfold\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1024)\n",
        "\n",
        "# for stratification\n",
        "y = df['label']\n",
        "\n",
        "# Note:\n",
        "# Each fold is a tuple ([train_index_values], [val_index_values])\n",
        "# fold_0, fold_1, fold_2, fold_3, fold_5 = kf.split(df, y)\n",
        "\n",
        "# Put the folds into a list. This is a list of tuples.\n",
        "fold_list = list(kf.split(df, y))\n",
        "\n",
        "train_df_list = []\n",
        "val_df_list = []\n",
        "\n",
        "for i, fold in enumerate(fold_list):\n",
        "\n",
        "    # map the train and val index values to dataframe rows\n",
        "    df_train = df[df.index.isin(fold[0])]\n",
        "    df_val = df[df.index.isin(fold[1])]\n",
        "    \n",
        "    train_df_list.append(df_train)\n",
        "    val_df_list.append(df_val)\n",
        "    \n",
        "    \n",
        "\n",
        "print(len(train_df_list))\n",
        "print(len(val_df_list))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XFMDhTVSgSN",
        "outputId": "7ac894d7-2476-4630-b596-3f805b9e3a3a"
      },
      "source": [
        "MODEL_TYPE = 'bert-base-multilingual-uncased'\n",
        "\n",
        "NUM_FOLDS = 5\n",
        "\n",
        "# Saving 5 TPU models will exceed the 4.9GB disk space.\n",
        "# Therefore, will will only train on 3 folds.\n",
        "NUM_FOLDS_TO_TRAIN = 3 \n",
        "\n",
        "L_RATE = 1e-5\n",
        "MAX_LEN = 256\n",
        "NUM_EPOCHS = 3\n",
        "BATCH_SIZE = 32\n",
        "NUM_CORES = os.cpu_count()\n",
        "\n",
        "NUM_CORES"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-uSzrJmSvAr",
        "outputId": "be3088cb-8893-4fef-ccb7-90f3333ba9e5"
      },
      "source": [
        "# For TPU\n",
        "\n",
        "device = xm.xla_device()\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xla:1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182,
          "referenced_widgets": [
            "2a06cbd941104680b27354cffe061b71",
            "cc8de10ae2634eb1b42ee136af842afa",
            "3a4f9ce3dc3447b187eb59da3046dc34",
            "43a0ab59e46d4af7a13b201da2f7161b",
            "9fa844a5a86f4a08a170201549529d8c",
            "489f5cac16504ef3aef2bccfc7022084",
            "96587defce0242bb96a21c6a522c569a",
            "deee31810754408682e46ff2fa9692af",
            "7159ddddb19f4c18af6546ef23675072",
            "6462562cc1d64dc3bf28200130ff5fe6",
            "39c74751d8b14d9eb1d2b8be347c4a87",
            "5dffa75af6ac4c6ab25d5913a6f585b4",
            "766427e28bb549c9acfe540bd7627ed3",
            "01898c1a5ca6498d978c9bb77208006c",
            "893c3e0618504bf9866f695c2a6c88ad",
            "41fce71aa236448399fec501e7f99523",
            "8f43c59f9eb946b48b939a4284feff17",
            "ae8fbeff7ffc415c9df0cc35a03c120e",
            "3cda1e9d370144b292643e2bc0d92586",
            "0d877cc58aa340648536b3eef644a020",
            "ab634f8787484194a8700eff2717c941",
            "160fdd7229524fa1978d9ef295280b82",
            "b3735e905ef24155a7bd33bb85a04f33",
            "82981cf66ac64cfb96f77bd390063cba"
          ]
        },
        "id": "Zl0nfxdMSyhF",
        "outputId": "35450cbf-9168-4389-c416-c78f49db1971"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_TYPE, do_lower_case=True)\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a06cbd941104680b27354cffe061b71",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=871891.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7159ddddb19f4c18af6546ef23675072",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f43c59f9eb946b48b939a4284feff17",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1715180.0, style=ProgressStyle(descriptâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rZgQTvCS3ZL"
      },
      "source": [
        "class BookDataset(Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "        self.df_data = df\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # get the sentence from the dataframe\n",
        "        sentence1 = self.df_data.loc[index, 'text']\n",
        "        \n",
        "        # Process the sentence\n",
        "        # ---------------------\n",
        "\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                    sentence1,           # Sentences to encode.\n",
        "                    add_special_tokens = True,      # Add '[CLS]' and '[SEP]'\n",
        "                    max_length = MAX_LEN,           # Pad or truncate all sentences.\n",
        "                    pad_to_max_length = True,\n",
        "                    truncation=True,\n",
        "                    return_attention_mask = True,   # Construct attn. masks.\n",
        "                    return_tensors = 'pt',          # Return pytorch tensors.\n",
        "               )  \n",
        "        \n",
        "        # These are torch tensors already.\n",
        "        padded_token_list = encoded_dict['input_ids'][0]\n",
        "        att_mask = encoded_dict['attention_mask'][0]\n",
        "        token_type_ids = encoded_dict['token_type_ids'][0]\n",
        "        \n",
        "        # Convert the target to a torch tensor\n",
        "        target = torch.tensor(label_to_ix[self.df_data.loc[index, 'label']])\n",
        "\n",
        "        sample = (padded_token_list, att_mask, token_type_ids, target)\n",
        "\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df_data)\n",
        "    \n",
        "    "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4cSdG7WUKRV"
      },
      "source": [
        "df_train = df_train.reset_index(drop=True)\n",
        "df_val = df_val.reset_index(drop=True)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMFNx6r9UYJU"
      },
      "source": [
        "train_data = BookDataset(df_train)\n",
        "val_data = BookDataset(df_val)\n",
        "\n",
        "\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=True,\n",
        "                                       num_workers=NUM_CORES)\n",
        "\n",
        "val_dataloader = torch.utils.data.DataLoader(val_data,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=True,\n",
        "                                       num_workers=NUM_CORES)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg6u3gOXUbqF",
        "outputId": "67a5fdf7-fcd2-49a0-ec2e-6d0c6efb80e6"
      },
      "source": [
        "print(len(train_dataloader))\n",
        "print(len(val_dataloader))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "834\n",
            "209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdlRoAlfUhyS",
        "outputId": "ddb48062-b772-480c-8429-33a884d623d7"
      },
      "source": [
        "# Get one train batch\n",
        "\n",
        "padded_token_list, att_mask, token_type_ids, target = next(iter(train_dataloader))\n",
        "\n",
        "print(padded_token_list.shape)\n",
        "print(att_mask.shape)\n",
        "print(token_type_ids.shape)\n",
        "print(target.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 256])\n",
            "torch.Size([32, 256])\n",
            "torch.Size([32, 256])\n",
            "torch.Size([32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwYUKvEqUxsc",
        "outputId": "a6b76516-b121-4615-f094-17d02946812a"
      },
      "source": [
        "# Get one val batch\n",
        "\n",
        "padded_token_list, att_mask, token_type_ids, target = next(iter(val_dataloader))\n",
        "\n",
        "print(padded_token_list.shape)\n",
        "print(att_mask.shape)\n",
        "print(token_type_ids.shape)\n",
        "print(target.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 256])\n",
            "torch.Size([32, 256])\n",
            "torch.Size([32, 256])\n",
            "torch.Size([32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0a42660b1e444df0af43ea9bd7ee2dfe",
            "84fac8b79e6340cda5bfb1388bbe448d",
            "db97c9ef97b747b88753d5fb15a9c1a7",
            "8f574fb8ab354f48a60faf07ab41ca3a",
            "9c62531570664a42b9a4807022224ec3",
            "98ff4409640144978bcc665adcae8416",
            "f3c2ea8747fb4365b57d3f38b717f0b1",
            "6193af98db5743e9a7b17a1e14b6916e",
            "ba7a33699e83492790e074166094ad08",
            "b366cbcb969f42578660efb3008f0299",
            "6770da38ecd7474b8f23d1945cfd3862",
            "7246e8eecb8b4e91b9e226cd0d6dc49d",
            "27d2e528084b4653be330f18eb7116f7",
            "1aed279f7c2549968687c002e736eb3f",
            "cdfa44037c494c569afbcb9d094b179e",
            "f053aec2600d412bb6b3b9af948481e6"
          ]
        },
        "id": "62w8yWlMU6Tc",
        "outputId": "4c3a5596-ed37-4470-bc9b-45663a878f5a"
      },
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    MODEL_TYPE, \n",
        "    num_labels = len(list(label_to_ix.values())), \n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False)\n",
        "\n",
        "# Send the model to the device.\n",
        "model.to(device)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a42660b1e444df0af43ea9bd7ee2dfe",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba7a33699e83492790e074166094ad08",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=672271273.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=13, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbAQa2XSVKYN"
      },
      "source": [
        "# Get one train batch\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data,\n",
        "                                        batch_size=8,\n",
        "                                        shuffle=True,\n",
        "                                       num_workers=NUM_CORES)\n",
        "\n",
        "batch = next(iter(train_dataloader))\n",
        "\n",
        "b_input_ids = batch[0].to(device)\n",
        "b_input_mask = batch[1].to(device)\n",
        "b_token_type_ids = batch[2].to(device)\n",
        "b_labels = batch[3].to(device)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzvvzFm4Vka4"
      },
      "source": [
        "outputs = model(b_input_ids, \n",
        "                token_type_ids=b_token_type_ids, \n",
        "                attention_mask=b_input_mask,\n",
        "                labels=b_labels)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKCffM19VsTY",
        "outputId": "3cf5d01c-3729-49b9-9896-1322496628d8"
      },
      "source": [
        "outputs"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequenceClassifierOutput([('loss',\n",
              "                           tensor(2.6252, device='xla:1', grad_fn=<NllLossBackward>)),\n",
              "                          ('logits',\n",
              "                           tensor([[ 0.2286,  0.1942,  0.0867,  0.0607, -0.1505,  0.0328,  0.1157, -0.0560,\n",
              "                                     0.3412, -0.2182,  0.0070, -0.1490, -0.1705],\n",
              "                                   [ 0.1526,  0.1709,  0.0410,  0.0819, -0.1269,  0.0329,  0.0905, -0.0598,\n",
              "                                     0.2985, -0.2244, -0.0078, -0.0790, -0.1738],\n",
              "                                   [ 0.2011,  0.1890,  0.0678,  0.0752, -0.1296,  0.0313,  0.1105, -0.0450,\n",
              "                                     0.2990, -0.2210, -0.0145, -0.1141, -0.1702],\n",
              "                                   [ 0.1865,  0.2054,  0.0766,  0.0770, -0.1439, -0.0028,  0.1385, -0.0488,\n",
              "                                     0.3504, -0.2388, -0.0451, -0.1007, -0.1458],\n",
              "                                   [ 0.1860,  0.1800,  0.0509,  0.0583, -0.1236,  0.0097,  0.1039, -0.0566,\n",
              "                                     0.3057, -0.2125, -0.0116, -0.1090, -0.1650],\n",
              "                                   [ 0.2105,  0.2105,  0.0723,  0.0811, -0.1662,  0.0188,  0.1509, -0.0662,\n",
              "                                     0.3423, -0.2413, -0.0133, -0.1184, -0.1295],\n",
              "                                   [ 0.2585,  0.2533,  0.1089,  0.0851, -0.1705,  0.0182,  0.1640, -0.0378,\n",
              "                                     0.3892, -0.2462, -0.0338, -0.1438, -0.1148],\n",
              "                                   [ 0.1794,  0.1803,  0.0833,  0.0621, -0.1441,  0.0554,  0.0908, -0.0818,\n",
              "                                     0.3226, -0.2378, -0.0163, -0.1015, -0.1644]], device='xla:1',\n",
              "                                  grad_fn=<AddmmBackward>))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ia9C1KfeVuEQ",
        "outputId": "b03075c3-448c-4a3f-d199-421fa1eab800"
      },
      "source": [
        "len(outputs)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFjmM_nqXjwS",
        "outputId": "1f0b5773-d732-4398-a1b5-469e6aab5bc1"
      },
      "source": [
        "preds = outputs[1].detach().cpu().numpy()\n",
        "\n",
        "y_true = b_labels.detach().cpu().numpy()\n",
        "y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "y_pred"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8, 8, 8, 8, 8, 8, 8, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fARMzsYXpUe",
        "outputId": "1bf56edf-9257-49eb-ca95-d33f4010bfd0"
      },
      "source": [
        "# This is the accuracy without any fine tuning.\n",
        "\n",
        "val_acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "val_acc"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvQY0l3VXsx4",
        "outputId": "57e50409-8723-468d-d95c-08e7561fcd69"
      },
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "# Set a seed value.\n",
        "seed_val = 1024\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "\n",
        "\n",
        "# Store the accuracy scores for each fold model in this list.\n",
        "# [[model_0 scores], [model_1 scores], [model_2 scores], [model_3 scores], [model_4 scores]]\n",
        "# [[ecpoch 1, epoch 2, ...], [ecpoch 1, epoch 2, ...], [ecpoch 1, epoch 2, ...], [ecpoch 1, epoch 2, ...], [ecpoch 1, epoch 2, ...]]\n",
        "\n",
        "# Create a list of lists to store the val acc results.\n",
        "# The number of items in this list will correspond to\n",
        "# the number of folds that the model is being trained on.\n",
        "fold_val_acc_list = []\n",
        "for i in range(0, NUM_FOLDS):\n",
        "    \n",
        "    # append an empty list\n",
        "    fold_val_acc_list.append([])\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "# For each epoch...\n",
        "for epoch in range(0, NUM_EPOCHS):\n",
        "    \n",
        "    print(\"\\nNum folds used for training:\", NUM_FOLDS_TO_TRAIN)\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch + 1, NUM_EPOCHS))\n",
        "    \n",
        "    # Get the number of folds\n",
        "    num_folds = len(train_df_list)\n",
        "\n",
        "    # For this epoch, store the val acc scores for each fold in this list.\n",
        "    # We will use this list to calculate the cv at the end of the epoch.\n",
        "    epoch_acc_scores_list = []\n",
        "    \n",
        "    # For each fold...\n",
        "    for fold_index in range(0, NUM_FOLDS_TO_TRAIN):\n",
        "        \n",
        "        print('\\n== Fold Model', fold_index)\n",
        "        \n",
        "        \n",
        "        # .........................\n",
        "        # Load the fold model\n",
        "        # .........................\n",
        "        \n",
        "        if epoch == 0:\n",
        "            \n",
        "            # define the model\n",
        "            model = BertForSequenceClassification.from_pretrained(\n",
        "            MODEL_TYPE, \n",
        "            num_labels = len(list(label_to_ix.values())),       \n",
        "            output_attentions = False, \n",
        "            output_hidden_states = False,\n",
        "            )\n",
        "            \n",
        "            # Send the model to the device.\n",
        "            model.to(device)\n",
        "            \n",
        "            optimizer = AdamW(model.parameters(),\n",
        "              lr = L_RATE, \n",
        "              eps = 1e-8\n",
        "            )\n",
        "            \n",
        "        else:\n",
        "        \n",
        "            # Get the fold model\n",
        "            path_model = 'model_' + str(fold_index) + '.bin'\n",
        "            model.load_state_dict(torch.load(path_model))\n",
        "\n",
        "            # Send the model to the device.\n",
        "            model.to(device)\n",
        "        \n",
        "        \n",
        "        \n",
        "        # .....................................\n",
        "        # Set up the train and val dataloaders\n",
        "        # .....................................\n",
        "        \n",
        "        \n",
        "        # Intialize the fold dataframes\n",
        "        df_train = train_df_list[fold_index]\n",
        "        df_val = val_df_list[fold_index]\n",
        "        \n",
        "        # Reset the indices or the dataloader won't work.\n",
        "        df_train = df_train.reset_index(drop=True)\n",
        "        df_val = df_val.reset_index(drop=True)\n",
        "    \n",
        "        # Create the dataloaders\n",
        "        train_data = BookDataset(df_train)\n",
        "        val_data = BookDataset(df_val)\n",
        "\n",
        "        train_dataloader = torch.utils.data.DataLoader(train_data,\n",
        "                                                batch_size=BATCH_SIZE,\n",
        "                                                shuffle=True,\n",
        "                                               num_workers=NUM_CORES)\n",
        "\n",
        "        val_dataloader = torch.utils.data.DataLoader(val_data,\n",
        "                                                batch_size=BATCH_SIZE,\n",
        "                                                shuffle=True,\n",
        "                                               num_workers=NUM_CORES)\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "       \n",
        "\n",
        "        # ========================================\n",
        "        #               Training\n",
        "        # ========================================\n",
        "        \n",
        "        stacked_val_labels = []\n",
        "        targets_list = []\n",
        "\n",
        "        print('Training...')\n",
        "\n",
        "        # put the model into train mode\n",
        "        model.train()\n",
        "\n",
        "        # This turns gradient calculations on and off.\n",
        "        torch.set_grad_enabled(True)\n",
        "\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_train_loss = 0\n",
        "\n",
        "        for i, batch in enumerate(train_dataloader):\n",
        "\n",
        "            train_status = 'Batch ' + str(i+1) + ' of ' + str(len(train_dataloader))\n",
        "\n",
        "            print(train_status, end='\\r')\n",
        "\n",
        "\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_token_type_ids = batch[2].to(device)\n",
        "            b_labels = batch[3].to(device)\n",
        "\n",
        "            model.zero_grad()        \n",
        "\n",
        "\n",
        "            outputs = model(b_input_ids, \n",
        "                        token_type_ids=b_token_type_ids, \n",
        "                        attention_mask=b_input_mask,\n",
        "                        labels=b_labels)\n",
        "\n",
        "            # Get the loss from the outputs tuple: (loss, logits)\n",
        "            loss = outputs[0]\n",
        "\n",
        "            # Convert the loss from a torch tensor to a number.\n",
        "            # Calculate the total loss.\n",
        "            total_train_loss = total_train_loss + loss.item()\n",
        "\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Perform a backward pass to calculate the gradients.\n",
        "            loss.backward()\n",
        "            \n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Use the optimizer to update Weights\n",
        "            \n",
        "            # Optimizer for GPU\n",
        "            # optimizer.step() \n",
        "            \n",
        "            # Optimizer for TPU\n",
        "            # https://pytorch.org/xla/\n",
        "            xm.optimizer_step(optimizer, barrier=True)\n",
        "            \n",
        "           \n",
        "\n",
        "\n",
        "        print('Train loss:' ,total_train_loss)\n",
        "\n",
        "\n",
        "        # ========================================\n",
        "        #               Validation\n",
        "        # ========================================\n",
        "\n",
        "        print('\\nValidation...')\n",
        "\n",
        "        # Put the model in evaluation mode.\n",
        "        model.eval()\n",
        "\n",
        "        # Turn off the gradient calculations.\n",
        "        # This tells the model not to compute or store gradients.\n",
        "        # This step saves memory and speeds up validation.\n",
        "        torch.set_grad_enabled(False)\n",
        "\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_val_loss = 0\n",
        "\n",
        "\n",
        "        for j, val_batch in enumerate(val_dataloader):\n",
        "\n",
        "            val_status = 'Batch ' + str(j+1) + ' of ' + str(len(val_dataloader))\n",
        "\n",
        "            print(val_status, end='\\r')\n",
        "\n",
        "            b_input_ids = val_batch[0].to(device)\n",
        "            b_input_mask = val_batch[1].to(device)\n",
        "            b_token_type_ids = val_batch[2].to(device)\n",
        "            b_labels = val_batch[3].to(device)      \n",
        "\n",
        "\n",
        "            outputs = model(b_input_ids, \n",
        "                    token_type_ids=b_token_type_ids, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "\n",
        "            # Get the loss from the outputs tuple: (loss, logits)\n",
        "            loss = outputs[0]\n",
        "\n",
        "            # Convert the loss from a torch tensor to a number.\n",
        "            # Calculate the total loss.\n",
        "            total_val_loss = total_val_loss + loss.item()\n",
        "\n",
        "            # Get the preds\n",
        "            preds = outputs[1]\n",
        "\n",
        "\n",
        "            # Move preds to the CPU\n",
        "            val_preds = preds.detach().cpu().numpy()\n",
        "\n",
        "            # Move the labels to the cpu\n",
        "            targets_np = b_labels.to('cpu').numpy()\n",
        "\n",
        "            # Append the labels to a numpy list\n",
        "            targets_list.extend(targets_np)\n",
        "\n",
        "            if j == 0:  # first batch\n",
        "                stacked_val_preds = val_preds\n",
        "\n",
        "            else:\n",
        "                stacked_val_preds = np.vstack((stacked_val_preds, val_preds))\n",
        "                \n",
        "                \n",
        "                \n",
        "        # .........................................\n",
        "        # Calculate the val accuracy for this fold\n",
        "        # .........................................      \n",
        "\n",
        "\n",
        "        # Calculate the validation accuracy\n",
        "        y_true = targets_list\n",
        "        y_pred = np.argmax(stacked_val_preds, axis=1)\n",
        "\n",
        "        val_acc = accuracy_score(y_true, y_pred)\n",
        "        \n",
        "        \n",
        "        epoch_acc_scores_list.append(val_acc)\n",
        "\n",
        "\n",
        "        print('Val loss:' ,total_val_loss)\n",
        "        print('Val acc: ', val_acc)\n",
        "        \n",
        "        \n",
        "        # .........................\n",
        "        # Save the best model\n",
        "        # .........................\n",
        "        \n",
        "        if epoch == 0:\n",
        "            \n",
        "            # Save the Model\n",
        "            model_name = 'model_' + str(fold_index) + '.bin'\n",
        "            torch.save(model.state_dict(), model_name)\n",
        "            print('Saved model as ', model_name)\n",
        "            \n",
        "        if epoch != 0:\n",
        "        \n",
        "            val_acc_list = fold_val_acc_list[fold_index]\n",
        "            best_val_acc = max(val_acc_list)\n",
        "            \n",
        "            if val_acc > best_val_acc:\n",
        "                # save the model\n",
        "                model_name = 'model_' + str(fold_index) + '.bin'\n",
        "                torch.save(model.state_dict(), model_name)\n",
        "                print('Val acc improved. Saved model as ', model_name)\n",
        "                \n",
        "                \n",
        "                \n",
        "        # .....................................\n",
        "        # Save the val_acc for this fold model\n",
        "        # .....................................\n",
        "        \n",
        "        # Note: Don't do this before the above 'Save Model' code or \n",
        "        # the save model code won't work. This is because the best_val_acc will\n",
        "        # become current val accuracy.\n",
        "                \n",
        "        # fold_val_acc_list is a list of lists.\n",
        "        # Each fold model has it's own list corresponding to the fold index.\n",
        "        # Here we choose a list corresponding to the fold number and append the acc score to that list.\n",
        "        fold_val_acc_list[fold_index].append(val_acc)\n",
        "        \n",
        "            \n",
        "\n",
        "        # Use the garbage collector to save memory.\n",
        "        gc.collect()\n",
        "        \n",
        "        \n",
        "    # .............................................................\n",
        "    # Calculate the CV accuracy score over all folds in this epoch\n",
        "    # .............................................................   \n",
        "        \n",
        "        \n",
        "    # Print the average val accuracy for all 5 folds\n",
        "    cv_acc = sum(epoch_acc_scores_list)/NUM_FOLDS_TO_TRAIN\n",
        "    print(\"\\nCV Acc:\", cv_acc)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Num folds used for training: 3\n",
            "======== Epoch 1 / 3 ========\n",
            "\n",
            "== Fold Model 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Train loss: 893.1927293241024\n",
            "\n",
            "Validation...\n",
            "Val loss: 79.39912250638008\n",
            "Val acc:  0.9002998500749625\n",
            "Saved model as  model_0.bin\n",
            "\n",
            "== Fold Model 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Train loss: 809.5130301490426\n",
            "\n",
            "Validation...\n",
            "Val loss: 77.70626430213451\n",
            "Val acc:  0.8970014992503749\n",
            "Saved model as  model_1.bin\n",
            "\n",
            "== Fold Model 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Train loss: 848.8112604618073\n",
            "\n",
            "Validation...\n",
            "Val loss: 71.49253100156784\n",
            "Val acc:  0.9056971514242879\n",
            "Saved model as  model_2.bin\n",
            "\n",
            "CV Acc: 0.9009995002498751\n",
            "\n",
            "Num folds used for training: 3\n",
            "======== Epoch 2 / 3 ========\n",
            "\n",
            "== Fold Model 0\n",
            "Training...\n",
            "Train loss: 208.2853031437844\n",
            "\n",
            "Validation...\n",
            "Val loss: 48.37440137937665\n",
            "Val acc:  0.9307346326836582\n",
            "Val acc improved. Saved model as  model_0.bin\n",
            "\n",
            "== Fold Model 1\n",
            "Training...\n",
            "Train loss: 205.85150121338665\n",
            "\n",
            "Validation...\n",
            "Val loss: 38.16099697351456\n",
            "Val acc:  0.948575712143928\n",
            "Val acc improved. Saved model as  model_1.bin\n",
            "\n",
            "== Fold Model 2\n",
            "Training...\n",
            "Train loss: 209.47454068809748\n",
            "\n",
            "Validation...\n",
            "Val loss: 35.10071453638375\n",
            "Val acc:  0.950824587706147\n",
            "Val acc improved. Saved model as  model_2.bin\n",
            "\n",
            "CV Acc: 0.9433783108445777\n",
            "\n",
            "Num folds used for training: 3\n",
            "======== Epoch 3 / 3 ========\n",
            "\n",
            "== Fold Model 0\n",
            "Training...\n",
            "Train loss: 103.5512673589401\n",
            "\n",
            "Validation...\n",
            "Val loss: 36.995951109565794\n",
            "Val acc:  0.9476761619190405\n",
            "Val acc improved. Saved model as  model_0.bin\n",
            "\n",
            "== Fold Model 1\n",
            "Training...\n",
            "Train loss: 102.51954444451258\n",
            "\n",
            "Validation...\n",
            "Val loss: 37.84040525439195\n",
            "Val acc:  0.9497751124437781\n",
            "Val acc improved. Saved model as  model_1.bin\n",
            "\n",
            "== Fold Model 2\n",
            "Training...\n",
            "Train loss: 109.64655773155391\n",
            "\n",
            "Validation...\n",
            "Val loss: 38.06211874820292\n",
            "Val acc:  0.9488755622188906\n",
            "\n",
            "CV Acc: 0.948775612193903\n",
            "CPU times: user 16min 51s, sys: 1min 58s, total: 18min 50s\n",
            "Wall time: 1h 47min 19s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQdXj2ZYYwJa",
        "outputId": "8cce8575-9025-4e3a-e82d-a242355c3eb7"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\n",
            "model_0.bin\n",
            "model_1.bin\n",
            "model_2.bin\n",
            "pytorch-xla-env-setup.py\n",
            "sample_data\n",
            "torch-nightly+20200515-cp37-cp37m-linux_x86_64.whl\n",
            "torchvision-nightly+20200515-cp37-cp37m-linux_x86_64.whl\n",
            "torch_xla-nightly+20200515-cp37-cp37m-linux_x86_64.whl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKKbFXsianEb",
        "outputId": "ca787595-eef3-4ce3-c949-8f5c07b00fa8"
      },
      "source": [
        "# Display the accuracy scores for each fold model.\n",
        "# For info: \n",
        "# Fold model 0 is only training on fold 0 in each epoch.\n",
        "# The same applies to the other fold models.\n",
        "\n",
        "fold_val_acc_list"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.9002998500749625, 0.9307346326836582, 0.9476761619190405],\n",
              " [0.8970014992503749, 0.948575712143928, 0.9497751124437781],\n",
              " [0.9056971514242879, 0.950824587706147, 0.9488755622188906],\n",
              " [],\n",
              " []]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yd1-XZMCaprK",
        "outputId": "42c09be0-3d95-45dd-e603-dba9f6a08705"
      },
      "source": [
        "MODEL_TYPE = 'xlm-roberta-base'\n",
        "\n",
        "\n",
        "L_RATE = 1e-5\n",
        "MAX_LEN = 256 #256\n",
        "\n",
        "NUM_EPOCHS = 3\n",
        "BATCH_SIZE = 32 #32\n",
        "NUM_CORES = os.cpu_count()\n",
        "\n",
        "NUM_CORES"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJxCBftda_ai",
        "outputId": "e053ead4-465e-49a9-b04e-640cad1a1d87"
      },
      "source": [
        "device = xm.xla_device()\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xla:1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CMKO0sdEbAEP",
        "outputId": "655843b2-2375-41ec-bf23-2621c8100162"
      },
      "source": [
        "df_train = train_df_list[0]\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21551</th>\n",
              "      <td>work and fondling her poodle when all the fair...</td>\n",
              "      <td>arthur_doyle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29546</th>\n",
              "      <td>mind the only time that i ever fancy myself un...</td>\n",
              "      <td>jane_austen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1676</th>\n",
              "      <td>the cliff â€™ â€˜ what be that level line of littl...</td>\n",
              "      <td>thomas_hardy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10471</th>\n",
              "      <td>large apartment roof floor open on three side ...</td>\n",
              "      <td>mark_twain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23142</th>\n",
              "      <td>whereon wa write a notice that the occupier se...</td>\n",
              "      <td>arthur_doyle</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text         label\n",
              "21551  work and fondling her poodle when all the fair...  arthur_doyle\n",
              "29546  mind the only time that i ever fancy myself un...   jane_austen\n",
              "1676   the cliff â€™ â€˜ what be that level line of littl...  thomas_hardy\n",
              "10471  large apartment roof floor open on three side ...    mark_twain\n",
              "23142  whereon wa write a notice that the occupier se...  arthur_doyle"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZKOx2OdbHiN",
        "outputId": "4c70e2a5-b126-4f9f-931f-72637aadbd5e"
      },
      "source": [
        "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
        "\n",
        "# xlm-roberta-large\n",
        "print('Loading XLMRoberta tokenizer...')\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained(MODEL_TYPE)\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading XLMRoberta tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYnWJZNDbK9_"
      },
      "source": [
        "df_train = df_train.reset_index(drop=True)\n",
        "df_val = df_val.reset_index(drop=True)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_yApdFMbNK5"
      },
      "source": [
        "class BookDataset(Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "        self.df_data = df\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # get the sentence from the dataframe\n",
        "        sentence1 = self.df_data.loc[index, 'text']\n",
        "\n",
        "        # Process the sentence\n",
        "        # ---------------------\n",
        "\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                    sentence1,           # Sentences to encode.\n",
        "                    add_special_tokens = True,      # Add the special tokens.\n",
        "                    max_length = MAX_LEN,           # Pad & truncate all sentences.\n",
        "                    pad_to_max_length = True,\n",
        "                    truncation=True,\n",
        "                    return_attention_mask = True,   # Construct attn. masks.\n",
        "                    return_tensors = 'pt',          # Return pytorch tensors.\n",
        "               )\n",
        "        \n",
        "        # These are torch tensors.\n",
        "        padded_token_list = encoded_dict['input_ids'][0]\n",
        "        att_mask = encoded_dict['attention_mask'][0]\n",
        "        \n",
        "        # Convert the target to a torch tensor\n",
        "        target = torch.tensor(label_to_ix[self.df_data.loc[index, 'label']])\n",
        "\n",
        "        sample = (padded_token_list, att_mask, target)\n",
        "\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df_data)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQOWRUfabkhq",
        "outputId": "c0816070-7a70-4b8a-c03c-5bb795aebbe0"
      },
      "source": [
        "train_data = BookDataset(df_train)\n",
        "val_data = BookDataset(df_val)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=True,\n",
        "                                       num_workers=NUM_CORES)\n",
        "\n",
        "val_dataloader = torch.utils.data.DataLoader(val_data,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=True,\n",
        "                                       num_workers=NUM_CORES)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(len(train_dataloader))\n",
        "print(len(val_dataloader))\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "834\n",
            "209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7380ba9f9a5840f9863a96d9acdc9d9c",
            "4c2631d423604f8db934ea627185eb46",
            "74c5e76e824a42b092ff78362f5419c6",
            "d49bfe5c5fec4e16b35d5bbeeeb27490",
            "666929547d0843aab08c95eeb13bdd7b",
            "11b97ccc12ee44428358867d75130914",
            "9b333e0b5cf2440e92ba4369dcdf6d6d",
            "ae0f30dc39d34807bda989bbe5c5e21f",
            "47fc8cfc56514fd98359bdde9e2aeb3e",
            "2531990d4a294b8c9bf94d954c31d57b",
            "6d88d22c07db4b02b19aba29e8911b3e",
            "f808bde5d0c943d8b828278447315438",
            "b2e4d310997e48ab898b902379873b7c",
            "51d2e8e6df0a475fb79aac98688b3965",
            "2f59a19c04684157bbf718c04d5375ce",
            "90024ab626a940e89b76cb4306cae6cf"
          ]
        },
        "id": "AkeKc-wifFXJ",
        "outputId": "3e34211e-e0d4-4be5-977e-85141ce82ab4"
      },
      "source": [
        "from transformers import XLMRobertaForSequenceClassification\n",
        "\n",
        "model = XLMRobertaForSequenceClassification.from_pretrained(\n",
        "    MODEL_TYPE, \n",
        "    num_labels = len(list(label_to_ix.values())), # The number of output labels. 2 for binary classification.\n",
        ")\n",
        "\n",
        "# Send the model to the device.\n",
        "model.to(device)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7380ba9f9a5840f9863a96d9acdc9d9c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=512.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47fc8cfc56514fd98359bdde9e2aeb3e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1115590446.0, style=ProgressStyle(descrâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLMRobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=13, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTn-u7wtfccs",
        "outputId": "9488df7f-5b46-41c4-861d-3e4d33944855"
      },
      "source": [
        "# Create a batch of train samples\n",
        "# We will set a small batch size of 8 so that the model's output can be easily displayed.\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data,\n",
        "                                        batch_size=8,\n",
        "                                        shuffle=True,\n",
        "                                       num_workers=NUM_CORES)\n",
        "\n",
        "b_input_ids, b_input_mask, b_labels = next(iter(train_dataloader))\n",
        "\n",
        "print(b_input_ids.shape)\n",
        "print(b_input_mask.shape)\n",
        "print(b_labels.shape)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_fgD2wNfXTX",
        "outputId": "e6f92f58-3426-45a8-9ef9-c7c72fdcc755"
      },
      "source": [
        "# Pass a batch of train samples to the model.\n",
        "\n",
        "batch = next(iter(train_dataloader))\n",
        "\n",
        "# Send the data to the device\n",
        "b_input_ids = batch[0].to(device)\n",
        "b_input_mask = batch[1].to(device)\n",
        "b_labels = batch[2].to(device)\n",
        "\n",
        "# Run the model\n",
        "outputs = model(b_input_ids, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels)\n",
        "\n",
        "# The ouput is a tuple (loss, preds).\n",
        "outputs"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequenceClassifierOutput([('loss', tensor(2.4561, device='xla:1')),\n",
              "                          ('logits',\n",
              "                           tensor([[-0.4175,  0.0644, -0.1566, -0.0722, -0.1279,  0.1817, -0.3389,  0.0524,\n",
              "                                    -0.1518, -0.1375,  0.0508,  0.1477, -0.2201],\n",
              "                                   [-0.4152,  0.0684, -0.1553, -0.0703, -0.1225,  0.1816, -0.3471,  0.0504,\n",
              "                                    -0.1494, -0.1424,  0.0461,  0.1557, -0.2161],\n",
              "                                   [-0.4128,  0.0733, -0.1573, -0.0694, -0.1246,  0.1785, -0.3462,  0.0543,\n",
              "                                    -0.1490, -0.1387,  0.0519,  0.1544, -0.2184],\n",
              "                                   [-0.4182,  0.0727, -0.1596, -0.0681, -0.1222,  0.1790, -0.3419,  0.0525,\n",
              "                                    -0.1483, -0.1367,  0.0499,  0.1492, -0.2180],\n",
              "                                   [-0.4185,  0.0690, -0.1567, -0.0685, -0.1252,  0.1812, -0.3436,  0.0533,\n",
              "                                    -0.1555, -0.1414,  0.0486,  0.1586, -0.2173],\n",
              "                                   [-0.4229,  0.0737, -0.1577, -0.0693, -0.1304,  0.1820, -0.3392,  0.0567,\n",
              "                                    -0.1533, -0.1369,  0.0513,  0.1512, -0.2158],\n",
              "                                   [-0.4195,  0.0672, -0.1672, -0.0721, -0.1280,  0.1813, -0.3473,  0.0543,\n",
              "                                    -0.1527, -0.1351,  0.0478,  0.1536, -0.2212],\n",
              "                                   [-0.4177,  0.0721, -0.1539, -0.0778, -0.1274,  0.1813, -0.3402,  0.0567,\n",
              "                                    -0.1522, -0.1320,  0.0482,  0.1485, -0.2152]], device='xla:1'))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMjUGPKYfhW6",
        "outputId": "ee32e636-c54d-4543-88b1-1b4d5ed11e8a"
      },
      "source": [
        "preds = outputs[1].detach().cpu().numpy()\n",
        "\n",
        "y_true = b_labels.detach().cpu().numpy()\n",
        "y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "y_pred"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 5, 5, 5, 5, 5, 5, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1F_KDCYufkoV",
        "outputId": "a281d2de-3182-4cba-c53f-440070834e05"
      },
      "source": [
        "# This is the accuracy without fine tuning.\n",
        "\n",
        "val_acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "val_acc"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY1UcdvZfpTX"
      },
      "source": [
        "# Define the optimizer\n",
        "optimizer = AdamW(model.parameters(),\n",
        "              lr = L_RATE, \n",
        "              eps = 1e-8 \n",
        "            )"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YL7531sf64T",
        "outputId": "24e5dbb4-a77d-4cd6-e730-4105195299c0"
      },
      "source": [
        "# Create the dataloaders.\n",
        "\n",
        "train_data = BookDataset(df_train)\n",
        "val_data = BookDataset(df_val)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=True,\n",
        "                                       num_workers=NUM_CORES)\n",
        "\n",
        "val_dataloader = torch.utils.data.DataLoader(val_data,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=True,\n",
        "                                       num_workers=NUM_CORES)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(len(train_dataloader))\n",
        "print(len(val_dataloader))\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "834\n",
            "209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_6K3NedeIUe",
        "outputId": "4d652af1-c5a8-4d1b-cf6b-6e11462dfa8a"
      },
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "# Set the seed.\n",
        "seed_val = 101\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "\n",
        "# For each epoch...\n",
        "for epoch in range(0, NUM_EPOCHS):\n",
        "    \n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch + 1, NUM_EPOCHS))\n",
        "    \n",
        "\n",
        "    stacked_val_labels = []\n",
        "    targets_list = []\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    print('Training...')\n",
        "    \n",
        "    # put the model into train mode\n",
        "    model.train()\n",
        "    \n",
        "    # This turns gradient calculations on and off.\n",
        "    torch.set_grad_enabled(True)\n",
        "\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "        \n",
        "        train_status = 'Batch ' + str(i) + ' of ' + str(len(train_dataloader))\n",
        "        \n",
        "        print(train_status, end='\\r')\n",
        "\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "\n",
        "        outputs = model(b_input_ids, \n",
        "                    attention_mask=b_input_mask,\n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # Get the loss from the outputs tuple: (loss, logits)\n",
        "        loss = outputs[0]\n",
        "        \n",
        "        # Convert the loss from a torch tensor to a number.\n",
        "        # Calculate the total loss.\n",
        "        total_train_loss = total_train_loss + loss.item()\n",
        "        \n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "        \n",
        "        \n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        \n",
        "        \n",
        "        # Use the optimizer to update the weights.\n",
        "        \n",
        "        # Optimizer for GPU\n",
        "        # optimizer.step() \n",
        "        \n",
        "        # Optimizer for TPU\n",
        "        # https://pytorch.org/xla/\n",
        "        xm.optimizer_step(optimizer, barrier=True)\n",
        "\n",
        "    \n",
        "    print('Train loss:' ,total_train_loss)\n",
        "\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    \n",
        "    print('\\nValidation...')\n",
        "\n",
        "    # Put the model in evaluation mode.\n",
        "    model.eval()\n",
        "\n",
        "    # Turn off the gradient calculations.\n",
        "    # This tells the model not to compute or store gradients.\n",
        "    # This step saves memory and speeds up validation.\n",
        "    torch.set_grad_enabled(False)\n",
        "    \n",
        "    \n",
        "    # Reset the total loss for this epoch.\n",
        "    total_val_loss = 0\n",
        "    \n",
        "\n",
        "    for j, batch in enumerate(val_dataloader):\n",
        "        \n",
        "        val_status = 'Batch ' + str(j) + ' of ' + str(len(val_dataloader))\n",
        "        \n",
        "        print(val_status, end='\\r')\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)      \n",
        "\n",
        "\n",
        "        outputs = model(b_input_ids, \n",
        "                attention_mask=b_input_mask, \n",
        "                labels=b_labels)\n",
        "        \n",
        "        # Get the loss from the outputs tuple: (loss, logits)\n",
        "        loss = outputs[0]\n",
        "        \n",
        "        # Convert the loss from a torch tensor to a number.\n",
        "        # Calculate the total loss.\n",
        "        total_val_loss = total_val_loss + loss.item()\n",
        "        \n",
        "\n",
        "        # Get the preds\n",
        "        preds = outputs[1]\n",
        "\n",
        "\n",
        "        # Move preds to the CPU\n",
        "        val_preds = preds.detach().cpu().numpy()\n",
        "        \n",
        "        # Move the labels to the cpu\n",
        "        targets_np = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Append the labels to a numpy list\n",
        "        targets_list.extend(targets_np)\n",
        "\n",
        "        if j == 0:  # first batch\n",
        "            stacked_val_preds = val_preds\n",
        "\n",
        "        else:\n",
        "            stacked_val_preds = np.vstack((stacked_val_preds, val_preds))\n",
        "\n",
        "    \n",
        "    # Calculate the validation accuracy\n",
        "    y_true = targets_list\n",
        "    y_pred = np.argmax(stacked_val_preds, axis=1)\n",
        "    \n",
        "    val_acc = accuracy_score(y_true, y_pred)\n",
        "    \n",
        "    \n",
        "    print('Val loss:' ,total_val_loss)\n",
        "    print('Val acc: ', val_acc)\n",
        "\n",
        "\n",
        "    # Save the Model\n",
        "    torch.save(model.state_dict(), 'model.pt')\n",
        "    \n",
        "    # Use the garbage collector to save memory.\n",
        "    gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZM84UOgfiZ4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}